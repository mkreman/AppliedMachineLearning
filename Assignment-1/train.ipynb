{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv files created in preparation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./sms+spam+collection/train.csv')\n",
    "valid_df = pd.read_csv('./sms+spam+collection/valid.csv')\n",
    "test_df = pd.read_csv('./sms+spam+collection/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some empty sms filed, hence removing them\n",
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 35911 stored elements and shape (4171, 6952)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=lambda x: x.split()).fit(train_df['processed sms'])\n",
    "sms_bow = bow_transformer.transform(train_df['processed sms'])\n",
    "sms_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(sms_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TF-IDF embeddings for train, valid and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 35911 stored elements and shape (4171, 6952)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df.label.map({'ham': 0, 'spam': 1}).values\n",
    "\n",
    "train_sms_tfidf = tfidf_transformer.transform(sms_bow)\n",
    "train_sms_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 5134 stored elements and shape (697, 6952)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_val = valid_df.label.map({'ham': 0, 'spam': 1}).values\n",
    "\n",
    "valid_sms_tfidf = tfidf_transformer.transform(bow_transformer.transform(valid_df['processed sms']))\n",
    "valid_sms_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 5363 stored elements and shape (697, 6952)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_test = test_df.label.map({'ham': 0, 'spam': 1}).values\n",
    "\n",
    "test_sms_tfidf = tfidf_transformer.transform(bow_transformer.transform(test_df['processed sms']))\n",
    "test_sms_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, x_train, y_train):\n",
    "    \"\"\"Fit the model on training data.\"\"\"\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_model(model, data):\n",
    "    \"\"\"Score the model on given data.\"\"\"\n",
    "    return model.predict(data)\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    \"\"\"Evaluate model predictions using accuracy and classification report.\"\"\"\n",
    "    return classification_report(y_true, y_pred)\n",
    "\n",
    "\n",
    "def validate_model(model, x_train, y_train, x_val, y_val, param_grid=None):\n",
    "    \"\"\"Validate the model by training, scoring, evaluating, and tuning hyperparameters.\"\"\"\n",
    "    # Fit model on training data\n",
    "    model = fit_model(model, x_train, y_train)\n",
    "    \n",
    "    # Score on train and validation data\n",
    "    y_train_pred = score_model(model, x_train)\n",
    "    y_val_pred = score_model(model, x_val)\n",
    "    \n",
    "    # Evaluate on train and validation data\n",
    "    train_report = evaluate_predictions(y_train, y_train_pred)\n",
    "    val_report = evaluate_predictions(y_val, y_val_pred)\n",
    "    \n",
    "    print(\"Train Report:\\n\", train_report)\n",
    "    print(\"Validation Report:\\n\", val_report)\n",
    "    \n",
    "    # Hyperparameter tuning if param_grid is provided\n",
    "    if param_grid:\n",
    "        # Since dataset is imbalanced, I am using `recall` to decide the parameter of the best model\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        model = grid_search.best_estimator_\n",
    "        print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tunning Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3611\n",
      "           1       1.00      0.99      0.99       560\n",
      "\n",
      "    accuracy                           1.00      4171\n",
      "   macro avg       1.00      0.99      1.00      4171\n",
      "weighted avg       1.00      1.00      1.00      4171\n",
      "\n",
      "Validation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       603\n",
      "           1       0.99      0.82      0.90        94\n",
      "\n",
      "    accuracy                           0.97       697\n",
      "   macro avg       0.98      0.91      0.94       697\n",
      "weighted avg       0.97      0.97      0.97       697\n",
      "\n",
      "Best Parameters: {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'C': [0.01, 0.1, 1, 10, 20],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2,3,4,5],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "best_svc = validate_model(\n",
    "    model=svc, \n",
    "    x_train=train_sms_tfidf, \n",
    "    y_train=y_train, \n",
    "    x_val=valid_sms_tfidf, \n",
    "    y_val=y_true_val, \n",
    "    param_grid=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       604\n",
      "           1       0.95      0.95      0.95        93\n",
      "\n",
      "    accuracy                           0.99       697\n",
      "   macro avg       0.97      0.97      0.97       697\n",
      "weighted avg       0.99      0.99      0.99       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = score_model(best_svc, test_sms_tfidf)\n",
    "print(evaluate_predictions(y_true_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tunning Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3611\n",
      "           1       0.99      0.78      0.87       560\n",
      "\n",
      "    accuracy                           0.97      4171\n",
      "   macro avg       0.98      0.89      0.93      4171\n",
      "weighted avg       0.97      0.97      0.97      4171\n",
      "\n",
      "Validation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       603\n",
      "           1       0.97      0.71      0.82        94\n",
      "\n",
      "    accuracy                           0.96       697\n",
      "   macro avg       0.96      0.85      0.90       697\n",
      "weighted avg       0.96      0.96      0.96       697\n",
      "\n",
      "Best Parameters: {'C': 0.001, 'penalty': None}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'C': [0.001, 0.1, 1.0, 10, 20],\n",
    "}\n",
    "\n",
    "best_lr = validate_model(\n",
    "    model=lr, \n",
    "    x_train=train_sms_tfidf, \n",
    "    y_train=y_train, \n",
    "    x_val=valid_sms_tfidf, \n",
    "    y_val=y_true_val, \n",
    "    param_grid=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       604\n",
      "           1       0.93      0.90      0.92        93\n",
      "\n",
      "    accuracy                           0.98       697\n",
      "   macro avg       0.96      0.95      0.95       697\n",
      "weighted avg       0.98      0.98      0.98       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = score_model(best_lr, test_sms_tfidf)\n",
    "print(evaluate_predictions(y_true_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tunning Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3611\n",
      "           1       1.00      1.00      1.00       560\n",
      "\n",
      "    accuracy                           1.00      4171\n",
      "   macro avg       1.00      1.00      1.00      4171\n",
      "weighted avg       1.00      1.00      1.00      4171\n",
      "\n",
      "Validation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       603\n",
      "           1       0.87      0.79      0.83        94\n",
      "\n",
      "    accuracy                           0.96       697\n",
      "   macro avg       0.92      0.88      0.90       697\n",
      "weighted avg       0.95      0.96      0.95       697\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_features': None, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_features': ['sqrt', 'log2', None, 1, 2]\n",
    "}\n",
    "\n",
    "best_tree = validate_model(\n",
    "    model=tree, \n",
    "    x_train=train_sms_tfidf, \n",
    "    y_train=y_train, \n",
    "    x_val=valid_sms_tfidf, \n",
    "    y_val=y_true_val, \n",
    "    param_grid=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       604\n",
      "           1       0.84      0.77      0.80        93\n",
      "\n",
      "    accuracy                           0.95       697\n",
      "   macro avg       0.90      0.88      0.89       697\n",
      "weighted avg       0.95      0.95      0.95       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = score_model(best_tree, test_sms_tfidf)\n",
    "print(evaluate_predictions(y_true_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing F1-Scores, Support Vector Classifier gives the best results and achieves $95\\%$ F1 score for `spam` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
